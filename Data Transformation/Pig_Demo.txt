
Create hfs directory for PIG :

hadoop fs -mkdir /user/pig_demo

Create pig_word_count_demo.txt with some text. Transfer it to /user/pig_demo

hadoop fs -put pig_word_count_demo.txt /user/pig_demo

1) pig_demo.pig:

load_data = load '/user/pig_demo/pig_word_count_demo.txt’;
dump load_data;

2) word_count.pig

lines = LOAD '/user/pig_demo/pig_word_count_demo.txt’ using PigStorage() AS (line:chararray);
words = FOREACH lines GENERATE FLATTEN(TOKENIZE(line)) AS word;
grouped = GROUP words by word;
wordCount = FOREACH grouped GENERATE group, COUNT(words);
DUMP wordCount;

3) Load data without a schema :->
  
   A = LOAD ‘/user/sqoop/all_tables/departments’ USING PigStorage(‘,’);

4) Load data with a schema :->
  
   A = LOAD ‘/user/sqoop/all_tables/departments’ USING PigStorage(‘,’) AS (department_id:int, department_name:chararray);

5) Load data from Hive :->
   
   Important Launch pig with Parameter  -useHcatalog :-> pig -useHCatalog
   customerDetails = LOAD 'xademo.customer_details' USING org.apache.hive.hcatalog.pig.HCatLoader();
   DUMP customerDetails;

6) Transform to match Hive schema :->
   
   First get the hfs location of a table using :
   DESCRIBE FORMATTED customer_details; -> Also get the delimiter by verifying field.delim Parameter
   Location:           	hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/xademo.db/customer_details
   field.delim         	|
 
   customer_details = LOAD 'hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/xademo.db/customer_details' USING PigStorage('|') AS (phone_number:chararray,plan:chararray,rec_date:chararray,status:chararray,balance:chararray,imei:chararray,region:chararray);
   

7) Grouping :->
   
   customer_details_hive = LOAD 'xademo.customer_details' USING org.apache.hive.hcatalog.pig.HCatLoader();
   customer_details_hive_noheader = FILTER customer_details_hive BY phone_number != 'PHONE_NUM';
   customer_details_group_all = GROUP customer_details_hive_noheader ALL;
   customer_details_count = FOREACH customer_details_group_all GENERATE COUNT_STAR(customer_details_hive_noheader) AS cnt;

   —To Filter out columns with NULLs
   customer_details_hive_no_null = FILTER customer_details_hive_noheader BY imei != ‘’;
   customer_details_hive_no_null_grouped = GROUP customer_details_hive_no_null ALL;
   customer_details_hive_no_null_count = FOREACH customer_details_hive_no_null_grouped GENERATE COUNT_STAR(customer_details_hive_no_null) AS cnt;
   
8) Grouping By Key :->
   
   orders = LOAD 'pig_demo.orders' USING org.apache.hive.hcatalog.pig.HCatLoader();
   group_by_status = GROUP orders BY order_status;
   count_by_order_status = FOREACH group_by_status GENERATE group, COUNT(orders) AS cnt;

9) Remove records with NULL Values :->
   
   a) Load Data Without Schema :->
      customer_details_without_schema = LOAD ‘/apps/hive/warehouse/xademo.db/customer_details’ USING PigStorage(‘|’);
      customer_details_no_null = FILTER customer_details_without_schema BY ($5 IS NOT NULL);
   
   b) Load Data With Schema :->
      customer_details_with_schema = LOAD 'hdfs://sandbox.hortonworks.com:8020/apps/hive/warehouse/xademo.db/customer_details' USING PigStorage('|') AS (phone_number:chararray,plan:chararray,rec_date:chararray,status:chararray,balance:chararray,imei:chararray,region:chararray);

   c) Load Data From Hive :->
      customer_details_hive = LOAD 'xademo.customer_details' USING org.apache.hive.hcatalog.pig.HCatLoader();

10) Store Data From Pig Relation to HDFS Folder :->
    
    STORE departments INTO '/user/pig_demo/store_folder/departments_one'; 
    departments = LOAD '/user/sqoop/all_tables/departments' USING PigStorage(',') AS (department_id:int, department_name:chararray);
    STORE departments INTO '/user/pig_demo/store_folder/departments_two' USING PigStorage('|');
    STORE departments INTO '/user/pig_demo/store_folder/departments_three’ USING BinStorage('|');
    STORE departments INTO '/user/pig_demo/store_folder/departments_four’ USING JsonStorage();

11) Store Data From Pig to Hive :->
    
    departments = LOAD '/user/sqoop/all_tables/departments' USING PigStorage(',') AS (department_id:int, department_name:chararray);
    STORE departments INTO 'pig_hive.departments' USING org.apache.hive.hcatalog.pig.HCatStorer();

12) Sort Pig Relation :->

    categories = LOAD '/user/sqoop/all_tables/categories' USING PigStorage(',');
    categories_orderby_dept_id = ORDER categories BY $1;

13) Remove Duplicates using Distinct :->

    orders = LOAD '/user/sqoop/all_tables/orders' USING PigStorage(',');
    order_status = FOREACH orders GENERATE $3;
    order_status_distinct = DISTINCT order_status;

14) Set Number of Reducers :->
 
    SET DEFAULT_PARALLEL 2; -> AT Script Level
    orders = LOAD 'pig_demo.orders' USING org.apache.hive.hcatalog.pig.HCatLoader();
    group_by_status = GROUP orders BY order_status PARALLEL 2;
    count_by_order_status = FOREACH group_by_status GENERATE group, COUNT(orders) AS cnt;

15) Join 1 :->

    orders = LOAD 'pig_demo.orders' USING org.apache.hive.hcatalog.pig.HCatLoader();
    order_items = LOAD 'pig_demo.order_items' USING org.apache.hive.hcatalog.pig.HCatLoader();
    orders_limit = LIMIT orders 10;
    orders_join = JOIN orders BY order_id, order_items BY order_item_order_id;

    To Get Count of Order_items :->
    order_items_group_all = GROUP order_items ALL;
    order_items_count = FOREACH order_items_group_all GENERATE COUNT_STAR(order_items) AS CNT;

    Transformation :->
    order_by_date = FOREACH orders_join GENERATE orders::order_date, order_items::order_item_subtotal;
    order_revenue_by_date = GROUP order_by_date BY orders::order_date;
    order_revenue = FOREACH order_revenue_by_date GENERATE group, SUM(order_by_date.order_items::order_item_subtotal) As RevenuePerDay;

16) Outer Join :->
    
    orders = LOAD 'pig_demo.orders' USING org.apache.hive.hcatalog.pig.HCatLoader();
    order_items = LOAD 'pig_demo.order_items' USING org.apache.hive.hcatalog.pig.HCatLoader();
    order_left_join = JOIN orders BY order_id LEFT OUTER, order_items BY order_item_order_id;
    order_left_join_filtered = FILTER order_left_join BY order_items::order_item_order_id IS NULL;

    order_left_grouped = GROUP order_left_join_filtered ALL;
    order_left_count = FOREACH order_left_grouped GENERATE group, COUNT_STAR(order_left_join_filtered) AS CNT;

17) Replicated Join :->



18) Run Pig Script in Tez :
    
    pig_run_tez.pig
    orders = LOAD 'pig_demo.orders' USING org.apache.hive.hcatalog.pig.HCatLoader();
    orders_grouped = GROUP orders ALL;
    orders_count = FOREACH orders_grouped GENERATE group, COUNT_STAR(orders) AS CNT;
    DUMP orders_count;

    To run in tez :->
    pig -f pig_run_tez.pig -useHCatalog -x tez

    To run in map reduce :->
    pig -f pig_run_tez.pig -useHCatalog -x map reduce

    To view wether Tez or MapReduce is default then :->
    Navigate to /etc/pig/conf
    vi pig.properties
    look for exectype 

19) Use UDF’s :->

    find / -name "*piggybank*.jar"
    /usr/hdp/2.5.0.0-1245/pig/piggybank.jar
    /usr/hdp/2.5.0.0-1245/pig/lib/piggybank.jar 
    REGISTER /usr/hdp/2.5.0.0-1245/pig/piggybank.jar;
    departments = LOAD 'pig_demo.departments' USING org.apache.hive.hcatalog.pig.HCatLoader();
    departments_upper = FOREACH departments GENERATE department_id, org.apache.pig.piggybank.evaluation.string.UPPER(department_name) AS Department_Name;

    TO Define Alias :->
    DEFINE Upper org.apache.pig.piggybank.evaluation.string.UPPER
    departments_upper = FOREACH departments GENERATE department_id, Upper(department_name) AS Department_Name;
    pig -f pig_UDF.pig -useHCatalog -x tez;