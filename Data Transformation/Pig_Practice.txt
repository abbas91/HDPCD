1) Create student.txt input file using :
 vi student.txt
John,18,4.0
Mary,19,3.8
Bill,20,3.9
Joe,18,3.8

2) Push it to hdfs :
hadoop fs -put student.txt /user/pig_demo

3)Create a relation with Schema:
A = LOAD '/user/pig_demo/student.txt' USING PigStorage(',') AS (name:chararray, age:int, gpa:float); 

4) To verify the schema :
DESCRIBE A;

5) To display result on the screen :
DUMP A;

6) TO define a Tuple in Schema :
	*Create data4.txt input file using :
		(3,8,9)
		(1,4,7)
		(2,5,8)
	* Load it to hdfs using :
	  hadoop fs -put data4.txt /user/pig_demo/data4.txt
	*Define Relation using :
	 A = LOAD ‘/user/pig_demo/data4.txt’ AS (T: tuple(f1:int, f2:int, f3:int));
	 DESCRIBE A;
	 DUMP A;

7) To define a Bag in Schema :

* Create data_bag.txt input file using:
	{(3,8,9)}
	{(1,4,7)}
	{(2,5,8)}
* Load it to hdfs using :
  hadoop fs -put data_bag.txt /user/pig_demo

* Define a Relation using :

  B = LOAD ‘/user/pig_demo/data_bag.txt’ AS (B: bag{T: tuple(f1:int,f2:int,f3:int)});
  DESCRIBE B;
  DUMP B;

8) To define a Map in Schema :
* Create data_map input file using:
  vi data_map.txt
	[name#bob]
	[age#55]
* Load it into hdfs using :
  hadoop fs -put data_map.txt /user/pig_demo

* Define a Relation using :
  
  C = LOAD ‘/user/pig_demo/data_map.txt’ AS (M: map []);
  DESCRIBE C;
  DUMP C;

9) Operators Demo :

Modulo:

* Create data_add_operation.txt using:
vi data_add_operation.txt
10,1,{(2,3),(4,6)}
10,3,{(2,3),(4,6)}
10,6,{(2,3),(4,6),(5,7)}

* Load it into hdfs using :
hadoop fs -put data_add_operation.txt /user/pig_demo

* Define a Relation using :

  A = LOAD ‘/user/pig_demo/data_add_operation.txt’ AS (f1:int, f2:int, B:bag{T:tuple(t1:int,t2:int)});
  X = FOREACH A GENERATE f1,f2, f1%f2;
  DUMP X;

* BINCOUNT Example :
  X = FOREACH A GENERATE f2, (f2==1?1:COUNT(B));
  DUMP X;

* Boolean Operation:
  vi data_boolean_operation.txt
  1       2       3
  4       2       1
  8       3       4
  4       3       3
  7       2       5
  8       4       3
  hadoop fs -put data_boolean_operation.txt
  A = LOAD '/user/pig_demo/data_boolean_operation.txt' AS (f1:int,f2:int,f3:int);
  X = FILTER A BY (f1==8) OR (NOT (f2+f3>f1));

10) Casting Demo :
hadoop fs -put data_boolean_operation.txt /user/pig_demo/data_cast.txt
A = LOAD '/user/pig_demo/data_cast.txt' AS (f1:int,f2:int,f3:int);
B = GROUP A BY f1;
X = FOREACH B GENERATE group, (chararray)COUNT(A) AS Total;
DESCRIBE X;
X: {group: int,Total: chararray} -> Int casted to chararray

11) ByteArray Casting Demo :
vi data_bytearray_cast.txt
(1,2,3)
(4,2,1)
(8,3,4)
hadoop fs -put data_bytearray_cast.txt /user/pig_demo
A = LOAD '/user/pig_demo/data_bytearray_cast.txt' AS fld:bytearray;
DUMP A;
DESCRIBE A; -> A: {fld: bytearray}
X = FOREACH A GENERATE (tuple(int,int,float))fld;
DESCRIBE X; -> X: {fld: (int,int,float)}

12) Comparison Operators :

vi data_comparision.txt
11      apache
12      hadoop
13      google
14      bigdata
15      java
16      hdfs
17      pig
18      hive
19      mapreduce

hadoop fs -put data_comparision.txt /user/pig_demo


A = LOAD '/user/pig_demo/data_comparision.txt' AS (f1:int,f2:chararray);

X = FILTER A BY (f1 == 18);
DUMP X; -> (18,hive)

X = FILTER A BY (f2 == 'hadoop');
DUMP X; -> (12,hadoop)

X = FILTER A BY (f2 matches 'hdfs');
DUMP X; -> (16,hdfs)

13) Relational Operators :

* Cross :->
  vi data_relation_one.txt
  1       2       3
  4       2       1  

  vi data_relation_two.txt
  2       4
  8       9
  1       3

  hadoop fs -put data_relation_one.txt data_relation_two.txt /user/pig_demo

  A = LOAD '/user/pig_demo/data_relation_one.txt' AS (a1:int,a2:int,a3:int);
  B = LOAD ‘/user/pig_demo/data_relation_two.txt’ AS (a1:int,a2:int);
  X = CROSS A,B;

* Distinct :->
  vi data_distinct.txt
  8       3       4
  1       2       3
  4       3       3
  4       3       3
  1       2       3

  hadoop fs -put data_distict.txt /user/pig_demo
  A = LOAD '/user/pig_demo/data_distinct.txt' AS (a1:int,a2:int,a3:int);
  X = DISTINCT A;

* Filter :->
  
  vi data_filter.txt
  1       2       3
  4       2       1
  8       4       3
  4       3       3
  7       2       5

  hadoop fs -put data_filter.txt /user/pig_demo

  A = LOAD '/user/pig_demo/data_filter.txt' AS (a1:int,a2:int,a3:int);
  X = FILTER A BY a3 == 3;

* FOREACH :->

  vi data_foreach.txt
  1       2       3
  4       2       1
  8       4       3
  4       3       3
  7       2       5
  A = LOAD '/user/pig_demo/data_foreach.txt' AS (a1:int,a2:int,a3:int);
  X = FOREACH A GENERATE a1;
  DUMP X;

* Group :->

  vi data_group.txt ( Tab Delimited)
  John	18 	4.0
  Mary	19	3.8
  Bill	20 	3.9
  Joe	18	3.8
  A = LOAD '/user/pig_demo/data_group.txt' AS (name:chararray, age:int,gpa:float);
  DUMP A;
  B = GROUP A BY age;
  (18,{(Joe,18,3.8),(John,18,4.0)})
  (19,{(Mary,19,3.8)})
  (20,{(Bill,20,3.9)})
